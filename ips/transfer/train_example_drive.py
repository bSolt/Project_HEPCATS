# -*- coding: utf-8 -*-
"""Train_Example_Drive.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YPc9hbMyuYZbIOB565ojHS6PrWwPznv1

# Pre-Trained Neural Network Transfer Learning Example

Using the standard image repository, ImageNet, two types of images are to be downloaded and then used to train an inception architecture nerual network to distinguish between them.

The two categories being used for the example are:
- Satellites, `wnid=n04137444`
- Airplanes, `wnid=n02691156`

The chosen pre-trained network is the inception-ResNet-v2 architecture [originially described here](https://arxiv.org/abs/1602.07261) This is a cutting edge architecture with over 100 layers and implementation of residual connection to improve training performance.

Note: Set Edit>Notebook Settings>Hardware Accelerator to GPU for fastest performance.

Firstly, the proper frameworks and libraries must be installed. In Google's colaboratory, the following code can be run, but it cannot be run in a standard Jupyter notebook. It can also be run from a linux or anaconda prompt.

The library `imagenetscraper` is used to download our training data. `pydot` is needed for a dependency.
"""

# !pip install imagenetscraper
# !pip install pydot

"""The next block of code is responsible for defining the `wnetid` values, and directories which will be used for either classification 1 or 0. The data is downloaded using `os` method `popen` to run the imagenetscraper scripts. This is going to be the longest block of code to execute because it's downloading like 2000 images."""

import os

# this is the satellites sysnet
pos_id = "n04265904" #rockets
# two sysnets are used for space to get more training data
space_id = ["n08500989","n08500819"]
air_id = ["n02691156"]

# store the images here
sat_dir = "./rockets/"
space_dir = "./space/"
air_dir = "./planes/"

neg_dir = air_dir

# do the downloading
print(os.popen("imagenetscraper " + pos_id +' '+ sat_dir).read())
for s in air_id:
  print(os.popen("imagenetscraper " + s +' '+ air_dir).read())

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
from PIL import Image
# from __future__ import print_function
import keras
from keras.utils import to_categorical
import os
from keras.preprocessing.image import ImageDataGenerator, load_img

"""After importing all the necesary code, including `numpy` et al, the following code block chooses the training and validation data. For the purposes of demonstration, 600 images are used for training and 300 are used for validation. Examples for each class are also shown by this block. The randomization can be changed by changing `np.random.seed()`. The important variables in this code are `train_list` and `test_list`. These lists contain the relative paths to all of the training images selected. It should be noted that these lists are sorted with the first half being the positive classification cases for both."""

# get lists from the image directories
sat_l = os.listdir(sat_dir)
neg_l = os.listdir(neg_dir)

# Count our images and report
n_sat = len(sat_l)
n_space = len(neg_l)
print("Successfully downloaded {} rocket picutres and {} no satellite pictures"
     .format(n_sat,n_space))

# Training Parameters #
# Define the number of images to use for each classification
N_im = 600
# Define ratio of images for training
rTrain = 0.75
rTest = 1-rTrain
# These are the total numbers for training images
# The images will be split into half satellite images and half non-sat images
nTrain = 2*round(N_im*rTrain)
nTest  = 2*round(N_im*rTest)

# Randomizing
np.random.seed(1)

# These are the indices used for training images
ind_sat = np.random.permutation(n_sat)[0:N_im]
ind_space = np.random.permutation(n_space)[0:N_im]

train_list = ([sat_dir + f for f in np.array(sat_l)[ind_sat[:nTrain//2]]] +
              [neg_dir + f for f in np.array(neg_l)[ind_space[:nTrain//2]]])

test_list  = ([sat_dir + f for f in np.array(sat_l)[ind_sat[nTrain//2:]]] +
              [neg_dir + f for f in np.array(neg_l)[ind_space[nTrain//2:]]])


# Plot the example images here
# Where the example images will be the first of the ordered images
fig,ax = plt.subplots(1,2,figsize=(12,6))
plt.subplot(1,2,1)
plt.grid('off')
plt.title("Example Satellite Image")
im = Image.open(sat_dir+sat_l[ind_sat[0]])
plt.imshow(im);

# Example of negative image
plt.subplot(1,2,2)
plt.grid('off')
plt.title("Example No Satellite Image")
im = Image.open(neg_dir+neg_l[ind_space[0]])
plt.imshow(im);

"""# Pre-Trained Network Setup & Feature Extraction

The next code block downloads the Pre-trained network configuration and weights.  Luckily the chosen network is included in keras, so this process if fairly straightforward. The code also displays a summary of the network's layers.
"""

from keras.applications.inception_resnet_v2 import InceptionResNetV2

# Note that the input_shape chosen here is to help with future datasets
inc_conv = InceptionResNetV2(weights='imagenet',
                  include_top=False,
                  input_shape=(256, 256, 3))

# Display layer information for reference
inc_conv.summary()

"""This is the part where we extract the features and use incpetion resnet. First the data generator settings and the batch size is defined.

The next block generates batches of training data. The feature array output by the feature detector network (The Inception-ResNet-v2 architecture) is of size 6 by 6 by 1536 for each image. These dimensions are flattened in the output because the classifier network will work on 1D data.

The subsequent block does the same for validation data.
"""

datagen = ImageDataGenerator(rescale=1./255)
batch_size = 20
epochs = 50

x_train = np.array([np.array(Image.open(fname).resize((256,256)).convert("RGB")) 
                    for fname in train_list])
y_train = np.concatenate((np.ones(nTrain//2), np.zeros(nTrain//2)))

# print(x_train.shape)

train_generator = datagen.flow(x_train, y_train, batch_size=batch_size)

train_features = np.zeros(shape=(nTrain, 6, 6, 1536))
train_labels = np.zeros(shape=(nTrain))

i = 0
for inputs_batch, labels_batch in train_generator:
    print("Working on training batch {}".format(i))
    features_batch = inc_conv.predict(inputs_batch)
    if ((i+1) * batch_size < nTrain):
      train_features[i * batch_size : (i + 1) * batch_size] = features_batch
      train_labels[i * batch_size : (i + 1) * batch_size] = labels_batch
    else:
      train_features[i * batch_size : ] = features_batch[0:nTrain-i*batch_size]
      train_labels[i * batch_size : ] = labels_batch[0:nTrain-i*batch_size]
    i += 1
    if i * batch_size >= nTrain:
        break
        
train_features = np.reshape(train_features, (nTrain, 6 * 6 * 1536))

x_test = np.array([np.array(Image.open(fname).resize((256,256)).convert("RGB")) 
                   for fname in test_list])
y_test = np.concatenate((np.ones(nTest//2), np.zeros(nTest//2)))

print(x_test[0].shape)

test_generator = datagen.flow(x_test, y_test, batch_size=batch_size)

test_features = np.zeros(shape=(nTest, 6, 6, 1536))
test_inputs = np.zeros(shape=(nTest, 256, 256, 3))
test_labels = np.zeros(shape=(nTest))

i = 0
for inputs_batch, labels_batch in test_generator:
    print("Working on test batch {}".format(i))
    features_batch = inc_conv.predict(inputs_batch)
    if((i+1)*batch_size < nTest):
      test_inputs[i * batch_size : (i + 1) * batch_size] = inputs_batch
      test_features[i * batch_size : (i + 1) * batch_size] = features_batch
      test_labels[i * batch_size : (i + 1) * batch_size] = labels_batch
    else:
      test_features[i * batch_size : ] = features_batch[0:nTest-i*batch_size]
      test_labels[i * batch_size : ] = labels_batch[0:nTest-i*batch_size]
    i += 1
    if i * batch_size >= nTest:
        break
        
test_features = np.reshape(test_features, (nTest, 6 * 6 * 1536))

"""# Building the Classifier Network

Next we must implement our own classifier network to be trained on the data. Luckily, using Keras functions, this processes is fairly straightforward.

The first block of code defines several metrics which will be used to gauge the network's performance. Included in this is the F1 score, which is a comprehensive measure of the network's performance on both true positives and false positives.
"""

#Do some metrics huh
from keras import backend as K

def recall(y_true, y_pred):
    """Recall metric.

    Only computes a batch-wise average of recall.

    Computes the recall, a metric for multi-label classification of
    how many relevant items are selected.
    """
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

def precision(y_true, y_pred):
    """Precision metric.

    Only computes a batch-wise average of precision.

    Computes the precision, a metric for multi-label classification of
    how many selected items are relevant.
    """
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

def f1(y_true, y_pred):
    """ F1 metric.
    The F1 metric is the marmonic mean of precision and recall
    """
    p = precision(y_true, y_pred)
    r = recall(y_true, y_pred)
    return 2*((p*r)/(p+r+K.epsilon()))

"""The next code block sets up and trains the classifier network. This simple classifier network only have input, hidden layer, dropout, and output layers. The input layer corresponds to the the 5 by 5 by 1536 array generated by the feature detector network, which was flattened earlier. These features are used to determine the values of the hidden layer which has 256 neurons. The following layer to this is a dropout layer. this dropout unit randomly ignores half of the values from the hidden layer. This is useful for preventing overfitting. The output layer is just a single neuron with a sigmoid activation. A sigmoid activation is used here because its output can be interpreted as a probability that the image is a satellite.

Other options specified here are in the last two lines of the code. First, the model was copiled and several options were chosen. The chosen optimizer is known as RMSprop which is known to have very good learning characteristics. The `lr` variabile passed to this stands for learning rate and simply paramaterizes how quickly the network attempts to change weight values by during training. The loss function was specified as a binary, cross-entropy loss becase this is also known to yield good learning values. Metrics that will be recorded are specified as accuracy, recall, and F1 score.

In the last line, training settings defined above are passed to the `fit()` method. Namely a batch size of 20 images and a total epoch count of 50.
"""

#Make this thang
from keras import models
from keras import layers
from keras import optimizers
 
# Sequential is the typical model structure
model = models.Sequential()
# The input layer is dense, or fully connected
model.add(layers.Dense(256, activation='relu', input_dim=6 * 6 * 1536))
# Dropout layer prevents overfitting
model.add(layers.Dropout(0.5))
# Output layer is a single neuron sigmoid
model.add(layers.Dense(1, activation='sigmoid'))

# Model options including metrics and loss function
model.compile(optimizer=optimizers.RMSprop(lr=2e-4),
              loss='binary_crossentropy',
              metrics=['acc',recall,f1])

# Fit this to our data please!
history = model.fit(train_features,
                    train_labels,
                    epochs=epochs,
                    batch_size=batch_size,
                    validation_data=(test_features,test_labels))

"""# Characterizing the Classifications

The first block of code for verifying network performance simply plots the information stored during the training process. There are plots for the metrics tracked in training, accuracy, recall, F1, as well as loss.
"""

plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

plt.plot(history.history['recall'])
plt.plot(history.history['val_recall'])
plt.title('Model recall')
plt.ylabel('Recall')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

plt.plot(history.history['f1'])
plt.plot(history.history['val_f1'])
plt.title('Model F1 score')
plt.ylabel('F1 score')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

from keras.utils import plot_model
plot_model(model, to_file='model.png')

"""This next section goes over errors in the validation data and displays a bunch of example images."""

# fnames = test_generator.filenames
 
ground_truth = test_labels
predictions = model.predict(test_features).reshape((300,))
# prob = model.predict(test_features)
 
errors = np.where((predictions>0.5) != ground_truth)[0]
print("No of errors = {}/{}".format(len(errors),nTest))

# Some old debug
# print(predictions.reshape((300,)).shape,ground_truth.shape)
# print(errors)
# # print((predictions>0.5)[0:10],ground_truth[0:10])
# print(predictions[64], ground_truth[64])

from itertools import chain
images = chain(errors,range(50))

for i in images:
#     pred_class = np.argmax(prob[errors[i]])
#     pred_label = idx2label[pred_class]
     
    print('Classification:{}, Prediction: {:.3f}'.format(
        ground_truth[i],
        predictions[i]))
     
    plt.imshow(test_inputs[i])
    plt.grid('off')
    plt.show()

"""The following is inteded to test an integrated classify images function and measure its speed."""

import time

def classify_image(image_data):
  n = image_data.shape[0]
  im_mat = np.asarray(image_data).reshape(n,256,256,3)
  features = inc_conv.predict(im_mat).reshape(n,6*6*1536)
  return model.predict(features)

N = 100;

# Make some examples
sats = np.random.randint(0,n_sat,N)
spaces = np.random.randint(0,n_space,N)

ex_list = ([sat_dir + f for f in np.array(sat_l)[sats]] + 
           [neg_dir + f for f in np.array(neg_l)[spaces]])

dt=0;

for i in range(2*N):
  im = Image.open(ex_list[i]).resize((256,256)).convert("RGB")
  im = np.array(im).reshape(1,256,256,3)
  t0 = time.time();
  prediction = classify_image(im)
  dt += time.time()-t0;
  print("Original Label:{:}, Prediction:{}".format(i<10,prediction))
  plt.imshow(im[0])
  plt.grid('off')
  plt.show()
  

print("Average classification time: {:8g}".format(dt/(2*N)))

from google.colab import files

model.save('prototype.h5')

files.download('prototype.h5')

files.download('prototype.h5')
print('Yay, my file downloaded correctly and easily!')

print(os.popen('ls').read())